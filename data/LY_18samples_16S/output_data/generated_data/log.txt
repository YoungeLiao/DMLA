(pyg) yangliao@yangs-MacBook-Pro scr % python main.py # 18 samples, 10000 epochs
feature shape:  (17, 128)
cuda is not available
Threshold: 0.4 
 Links number: 1542 
 Average Links: 12.046875
Adj: (128, 128) Edges: 1542
X: (128, 17)
Adj: (128, 128) Edges: 1542
X: (128, 17)
-----------Deep Graph Infomax-------------
/Users/yangliao/opt/anaconda3/envs/pyg/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Epoch: 100, Loss: 1.2879
Epoch: 200, Loss: 1.2285
Epoch: 300, Loss: 1.1454
Epoch: 400, Loss: 1.0855
Epoch: 500, Loss: 1.0384
Epoch: 600, Loss: 0.9669
Epoch: 700, Loss: 0.8955
Epoch: 800, Loss: 0.8951
Epoch: 900, Loss: 0.8527
Epoch: 1000, Loss: 0.8088
Epoch: 1100, Loss: 0.7562
Epoch: 1200, Loss: 0.7087
Epoch: 1300, Loss: 0.7687
Epoch: 1400, Loss: 0.6301
Epoch: 1500, Loss: 0.7048
Epoch: 1600, Loss: 0.6139
Epoch: 1700, Loss: 0.6220
Epoch: 1800, Loss: 0.6379
Epoch: 1900, Loss: 0.5963
Epoch: 2000, Loss: 0.5758
Epoch: 2100, Loss: 0.4605
Epoch: 2200, Loss: 0.4881
Epoch: 2300, Loss: 0.6133
Epoch: 2400, Loss: 0.4490
Epoch: 2500, Loss: 0.4783
Epoch: 2600, Loss: 0.4658
Epoch: 2700, Loss: 0.4838
Epoch: 2800, Loss: 0.4600
Epoch: 2900, Loss: 0.5450
Epoch: 3000, Loss: 0.4730
Epoch: 3100, Loss: 0.5245
Epoch: 3200, Loss: 0.4844
Epoch: 3300, Loss: 0.3429
Epoch: 3400, Loss: 0.3473
Epoch: 3500, Loss: 0.4035
Epoch: 3600, Loss: 0.3301
Epoch: 3700, Loss: 0.2876
Epoch: 3800, Loss: 0.4360
Epoch: 3900, Loss: 0.3521
Epoch: 4000, Loss: 0.3389
Epoch: 4100, Loss: 0.3551
Epoch: 4200, Loss: 0.3712
Epoch: 4300, Loss: 0.2263
Epoch: 4400, Loss: 0.3637
Epoch: 4500, Loss: 0.2836
Epoch: 4600, Loss: 0.4397
Epoch: 4700, Loss: 0.5815
Epoch: 4800, Loss: 0.4277
Epoch: 4900, Loss: 0.4075
Epoch: 5000, Loss: 0.2913
Epoch: 5100, Loss: 0.2208
Epoch: 5200, Loss: 0.4001
Epoch: 5300, Loss: 0.3088
Epoch: 5400, Loss: 0.3067
Epoch: 5500, Loss: 0.4298
Epoch: 5600, Loss: 0.3068
Epoch: 5700, Loss: 0.2776
Epoch: 5800, Loss: 0.3213
Epoch: 5900, Loss: 0.2545
Epoch: 6000, Loss: 0.3345
Epoch: 6100, Loss: 0.3163
Epoch: 6200, Loss: 0.2558
Epoch: 6300, Loss: 0.2919
Epoch: 6400, Loss: 0.3693
Epoch: 6500, Loss: 0.3045
Epoch: 6600, Loss: 0.2441
Epoch: 6700, Loss: 0.2318
Epoch: 6800, Loss: 0.2100
Epoch: 6900, Loss: 0.2247
Epoch: 7000, Loss: 0.2565
Epoch: 7100, Loss: 0.2704
Epoch: 7200, Loss: 0.3657
Epoch: 7300, Loss: 0.3015
Epoch: 7400, Loss: 0.4344
Epoch: 7500, Loss: 0.1936
Epoch: 7600, Loss: 0.2751
Epoch: 7700, Loss: 0.1955
Epoch: 7800, Loss: 0.2279
Epoch: 7900, Loss: 0.1741
Epoch: 8000, Loss: 0.1893
Epoch: 8100, Loss: 0.2774
Epoch: 8200, Loss: 0.2735
Epoch: 8300, Loss: 0.3261
Epoch: 8400, Loss: 0.1769
Epoch: 8500, Loss: 0.2533
Epoch: 8600, Loss: 0.2459
Epoch: 8700, Loss: 0.2542
Epoch: 8800, Loss: 0.1686
Epoch: 8900, Loss: 0.2861
Epoch: 9000, Loss: 0.2773
Epoch: 9100, Loss: 0.3269
Epoch: 9200, Loss: 0.3082
Epoch: 9300, Loss: 0.2645
Epoch: 9400, Loss: 0.2193
Epoch: 9500, Loss: 0.3953
Epoch: 9600, Loss: 0.2168
Epoch: 9700, Loss: 0.1993
Epoch: 9800, Loss: 0.1932
Epoch: 9900, Loss: 0.2046
Epoch: 10000, Loss: 0.1823
Training time in seconds:  148
-----------Clustering-------------
Shape of data to PCA: (128, 256)
Shape of data output by PCA: (128, 30)
PCA recover: 0.9999294
Shape of data to cluster: (128, 30)
/Users/yangliao/opt/anaconda3/envs/pyg/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: 
Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at
the same time. Both libraries are known to be incompatible and this
can cause random crashes or deadlocks on Linux when loaded in the
same Python program.
Using threadpoolctl may cause crashes or deadlocks. For more
information and possible workarounds, please see
    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md

  warnings.warn(msg, RuntimeWarning)
SCI score (Clustering quality) is: 0.5830121
(pyg) yangliao@yangs-MacBook-Pro scr % python main.py # 18 samples, 20000 epochs
feature shape:  (17, 128)
cuda is not available
Threshold: 0.4 
 Links number: 1542 
 Average Links: 12.046875
Adj: (128, 128) Edges: 1542
X: (128, 17)
Adj: (128, 128) Edges: 1542
X: (128, 17)
-----------Deep Graph Infomax-------------
/Users/yangliao/opt/anaconda3/envs/pyg/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
Epoch: 100, Loss: 1.3774
Epoch: 200, Loss: 1.2967
Epoch: 300, Loss: 1.2718
Epoch: 400, Loss: 1.2069
Epoch: 500, Loss: 1.1485
Epoch: 600, Loss: 1.1064
Epoch: 700, Loss: 1.0532
Epoch: 800, Loss: 1.0426
Epoch: 900, Loss: 1.0119
Epoch: 1000, Loss: 0.9534
Epoch: 1100, Loss: 0.9387
Epoch: 1200, Loss: 0.8529
Epoch: 1300, Loss: 0.8172
Epoch: 1400, Loss: 0.8092
Epoch: 1500, Loss: 0.8082
Epoch: 1600, Loss: 0.7053
Epoch: 1700, Loss: 0.7533
Epoch: 1800, Loss: 0.7634
Epoch: 1900, Loss: 0.6689
Epoch: 2000, Loss: 0.6659
Epoch: 2100, Loss: 0.6577
Epoch: 2200, Loss: 0.5418
Epoch: 2300, Loss: 0.5516
Epoch: 2400, Loss: 0.5180
Epoch: 2500, Loss: 0.4314
Epoch: 2600, Loss: 0.5820
Epoch: 2700, Loss: 0.5138
Epoch: 2800, Loss: 0.4212
Epoch: 2900, Loss: 0.4862
Epoch: 3000, Loss: 0.4838
Epoch: 3100, Loss: 0.4896
Epoch: 3200, Loss: 0.5099
Epoch: 3300, Loss: 0.3655
Epoch: 3400, Loss: 0.4948
Epoch: 3500, Loss: 0.3596
Epoch: 3600, Loss: 0.3979
Epoch: 3700, Loss: 0.3015
Epoch: 3800, Loss: 0.3647
Epoch: 3900, Loss: 0.4385
Epoch: 4000, Loss: 0.3524
Epoch: 4100, Loss: 0.2711
Epoch: 4200, Loss: 0.3621
Epoch: 4300, Loss: 0.3695
Epoch: 4400, Loss: 0.3215
Epoch: 4500, Loss: 0.3820
Epoch: 4600, Loss: 0.4200
Epoch: 4700, Loss: 0.3719
Epoch: 4800, Loss: 0.4749
Epoch: 4900, Loss: 0.2991
Epoch: 5000, Loss: 0.3781
Epoch: 5100, Loss: 0.3681
Epoch: 5200, Loss: 0.4520
Epoch: 5300, Loss: 0.2296
Epoch: 5400, Loss: 0.3181
Epoch: 5500, Loss: 0.4747
Epoch: 5600, Loss: 0.3040
Epoch: 5700, Loss: 0.2592
Epoch: 5800, Loss: 0.2221
Epoch: 5900, Loss: 0.4347
Epoch: 6000, Loss: 0.3875
Epoch: 6100, Loss: 0.2125
Epoch: 6200, Loss: 0.2932
Epoch: 6300, Loss: 0.2515
Epoch: 6400, Loss: 0.4148
Epoch: 6500, Loss: 0.4023
Epoch: 6600, Loss: 0.2064
Epoch: 6700, Loss: 0.3240
Epoch: 6800, Loss: 0.1934
Epoch: 6900, Loss: 0.4304
Epoch: 7000, Loss: 0.2511
Epoch: 7100, Loss: 0.2254
Epoch: 7200, Loss: 0.2420
Epoch: 7300, Loss: 0.2548
Epoch: 7400, Loss: 0.3020
Epoch: 7500, Loss: 0.3358
Epoch: 7600, Loss: 0.2182
Epoch: 7700, Loss: 0.2319
Epoch: 7800, Loss: 0.4619
Epoch: 7900, Loss: 0.2505
Epoch: 8000, Loss: 0.2596
Epoch: 8100, Loss: 0.3871
Epoch: 8200, Loss: 0.3948
Epoch: 8300, Loss: 0.2652
Epoch: 8400, Loss: 0.1972
Epoch: 8500, Loss: 0.2739
Epoch: 8600, Loss: 0.2754
Epoch: 8700, Loss: 0.1633
Epoch: 8800, Loss: 0.2623
Epoch: 8900, Loss: 0.3332
Epoch: 9000, Loss: 0.3033
Epoch: 9100, Loss: 0.2191
Epoch: 9200, Loss: 0.4181
Epoch: 9300, Loss: 0.2207
Epoch: 9400, Loss: 0.2555
Epoch: 9500, Loss: 0.1769
Epoch: 9600, Loss: 0.2001
Epoch: 9700, Loss: 0.3020
Epoch: 9800, Loss: 0.2228
Epoch: 9900, Loss: 0.4361
Epoch: 10000, Loss: 0.1704
Epoch: 10100, Loss: 0.1664
Epoch: 10200, Loss: 0.2259
Epoch: 10300, Loss: 0.3168
Epoch: 10400, Loss: 0.2391
Epoch: 10500, Loss: 0.1855
Epoch: 10600, Loss: 0.1444
Epoch: 10700, Loss: 0.2097
Epoch: 10800, Loss: 0.3266
Epoch: 10900, Loss: 0.1844
Epoch: 11000, Loss: 0.2158
Epoch: 11100, Loss: 0.3126
Epoch: 11200, Loss: 0.3427
Epoch: 11300, Loss: 0.1992
Epoch: 11400, Loss: 0.1469
Epoch: 11500, Loss: 0.3227
Epoch: 11600, Loss: 0.2812
Epoch: 11700, Loss: 0.1593
Epoch: 11800, Loss: 0.3092
Epoch: 11900, Loss: 0.1609
Epoch: 12000, Loss: 0.2712
Epoch: 12100, Loss: 0.2049
Epoch: 12200, Loss: 0.1511
Epoch: 12300, Loss: 0.2471
Epoch: 12400, Loss: 0.1776
Epoch: 12500, Loss: 0.2091
Epoch: 12600, Loss: 0.1495
Epoch: 12700, Loss: 0.1392
Epoch: 12800, Loss: 0.1422
Epoch: 12900, Loss: 0.3207
Epoch: 13000, Loss: 0.2748
Epoch: 13100, Loss: 0.1976
Epoch: 13200, Loss: 0.1893
Epoch: 13300, Loss: 0.1984
Epoch: 13400, Loss: 0.1490
Epoch: 13500, Loss: 0.2776
Epoch: 13600, Loss: 0.2890
Epoch: 13700, Loss: 0.1050
Epoch: 13800, Loss: 0.1131
Epoch: 13900, Loss: 0.3159
Epoch: 14000, Loss: 0.1558
Epoch: 14100, Loss: 0.1873
Epoch: 14200, Loss: 0.1423
Epoch: 14300, Loss: 0.1966
Epoch: 14400, Loss: 0.1989
Epoch: 14500, Loss: 0.2054
Epoch: 14600, Loss: 0.2202
Epoch: 14700, Loss: 0.1088
Epoch: 14800, Loss: 0.2842
Epoch: 14900, Loss: 0.3021
Epoch: 15000, Loss: 0.3827
Epoch: 15100, Loss: 0.1969
Epoch: 15200, Loss: 0.1272
Epoch: 15300, Loss: 0.1538
Epoch: 15400, Loss: 0.1440
Epoch: 15500, Loss: 0.2118
Epoch: 15600, Loss: 0.2194
Epoch: 15700, Loss: 0.2330
Epoch: 15800, Loss: 0.3951
Epoch: 15900, Loss: 0.1461
Epoch: 16000, Loss: 0.1796
Epoch: 16100, Loss: 0.2508
Epoch: 16200, Loss: 0.1734
Epoch: 16300, Loss: 0.1427
Epoch: 16400, Loss: 0.1746
Epoch: 16500, Loss: 0.0895
Epoch: 16600, Loss: 0.1377
Epoch: 16700, Loss: 0.1137
Epoch: 16800, Loss: 0.2490
Epoch: 16900, Loss: 0.1196
Epoch: 17000, Loss: 0.1360
Epoch: 17100, Loss: 0.1909
Epoch: 17200, Loss: 0.2375
Epoch: 17300, Loss: 0.2550
Epoch: 17400, Loss: 0.2856
Epoch: 17500, Loss: 0.2446
Epoch: 17600, Loss: 0.2074
Epoch: 17700, Loss: 0.1392
Epoch: 17800, Loss: 0.2091
Epoch: 17900, Loss: 0.1992
Epoch: 18000, Loss: 0.1663
Epoch: 18100, Loss: 0.1900
Epoch: 18200, Loss: 0.1959
Epoch: 18300, Loss: 0.1158
Epoch: 18400, Loss: 0.1467
Epoch: 18500, Loss: 0.2567
Epoch: 18600, Loss: 0.1940
Epoch: 18700, Loss: 0.1306
Epoch: 18800, Loss: 0.3638
Epoch: 18900, Loss: 0.1703
Epoch: 19000, Loss: 0.0899
Epoch: 19100, Loss: 0.0855
Epoch: 19200, Loss: 0.1288
Epoch: 19300, Loss: 0.1489
Epoch: 19400, Loss: 0.2194
Epoch: 19500, Loss: 0.1387
Epoch: 19600, Loss: 0.1796
Epoch: 19700, Loss: 0.2400
Epoch: 19800, Loss: 0.1174
Epoch: 19900, Loss: 0.1844
Epoch: 20000, Loss: 0.1309
Training time in seconds:  284
-----------Clustering-------------
Shape of data to PCA: (128, 256)
Shape of data output by PCA: (128, 30)
PCA recover: 0.9999516
Shape of data to cluster: (128, 30)
/Users/yangliao/opt/anaconda3/envs/pyg/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: 
Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at
the same time. Both libraries are known to be incompatible and this
can cause random crashes or deadlocks on Linux when loaded in the
same Python program.
Using threadpoolctl may cause crashes or deadlocks. For more
information and possible workarounds, please see
    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md

  warnings.warn(msg, RuntimeWarning)
SCI score (Clustering quality) is: 0.5929531